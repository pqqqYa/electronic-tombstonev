# 第二章 静态测试技术总结

## 一、静态测试技术概要

  

1. **定义**
    - 不在计算机上实际执行所测试软件的测试，包括对需求规约、设计规约、代码及文档的检查和静态结构分析等。
2. **特点**
    - 可借助软件工具自动进行，成本低、效率高，能在软件开发生命周期早期发现缺陷。

## 二、评审技术概述

  

1. **评审**
    - 由同行对软件工作产品进行审查，目的是识别错误、缺陷及改进之处。
    - 包括非正式评审（开发中，无明确定义）和正式评审（工作产品完成后，遵循定义过程）。
2. **评审过程**
    - 计划、准备、自评审、评审会、重新修改、分析总结阶段。
3. **责任和角色**
    - 协调负责人、作者、记录员、评审者等，不同评审形式角色和人数可能不同。

## 三、代码检查

  

1. **类型**
    - 桌面检查、代码审查和走查。
2. **目的**
    - 检查代码与设计一致性、遵循标准、可读性、逻辑正确性、结构合理性等。
3. **内容**
    - 变量、标号交叉引用表检查，子程序、宏、函数调用验证，等价性、常量检查，标准、风格检查，控制流比较等。
4. **编码规范**
    - 总体、封装、多态继承、重载规范，代码格式、注释、命名规范。
5. **代码缺陷检查表**
    - 包含易错点和典型错误。
6. **走查过程**
    - 计划走查会议、走查产品、走查会议、解决问题、记录走查、返工产品。
7. **优势**
    - 能快速找到错误，发现较多逻辑设计和编码缺陷，看到问题本身。可自动化测试。

## 四、正规技术评审

  

1. **定义**
    - 由评审者按规范步骤检查软件需求、设计等技术文档，消除错误或缺陷。
2. **目的**
    - 发现功能、逻辑、实现错误，验证需求符合度，确认符合规范标准，保证统一开发模式，便于项目管理。
3. **评审小组成员**
    - 评审员、主持人、宣读员、记录员、作者，至少 3 人，一般 4 - 7 人。
4. **技术评审活动过程**
    - 计划、预备会、会前准备、评审会、修正错误、复审、复核。
5. **注意事项**
    - 针对材料，控制评审时间，限制争论，阐明问题。

## 五、面向对象分析和设计的静态测试

  

1. **面向对象分析规约的静态测试**
    - 分析方式：围绕映射问题空间展开，将实例抽象为对象。
    - 测试内容：对需求、确认对象、结构、主题、属性与实例关联、服务与消息关联的测试。
2. **面向对象设计规约的静态测试**
    - 设计内容：对象抽象、系统结构设计、类及关系设计、界面和数据库设计等。
    - 测试内容：对确认的类、构造的类层次结构、类库支持、系统架构的测试。
    - 测试方法：建立消息序列图，通过交互和行为模型进行测试，测试报告需专家审核。

# 第三章 动态测试技术总结

## 一、黑盒测试技术

  

1. **边界值分析法**
    - 基于变量定义域或值域分析设计测试用例。
    - 包括基本边界值分析（基于单缺陷假设，对每个变量取 5 个值，n 个变量有 4n + 1 个测试用例）、健壮性边界分析（扩展基本边界值分析，考虑超边界值，测试用例数为 6n + 1）、最坏情况边界分析（基于多缺陷假设，对变量取值集合做笛卡尔积，n 变量有 5n 个测试用例）等。
    - 设计原则：考虑输入输出范围、个数、有序集合、内部数据结构等边界情况，分析变量独立性等。
2. **等价类测试法**
    - 对变量划分等价类，用等价类子集设计测试用例，保证完备性和无冗余性。
    - 包括弱一般等价类测试（基于单缺陷假设，测试用例个数为变量划分区间最多的有效区间个数）、强一般等价类测试（基于多缺陷假设，测试用例为不同变量有效等价类取值集合笛卡尔积元素）、弱健壮等价类测试（在弱一般等价类基础上考虑无效等价类，测试用例由两部分构成）、强健壮等价类测试（在强一般等价类基础上考虑无效等价类，测试用例由两部分构成且考虑多变量无效情况）。
    - 设计原则：根据输入输出条件规定，确定有效和无效等价类，必要时进一步细分等价类。
3. **错误推测法**
    - 基于经验和直觉推测程序错误，针对性设计测试用例，不是独立测试技术，是提升测试有效性的技能。
4. **因果图法**
    - 考虑输入条件组合及输出对输入的因果关系设计测试用例，最终生成判定表。
    - 步骤：分割功能说明书、识别原因和结果并编号、画因果图基本符号、加约束条件、画判定表、为判定表列设计测试用例。
5. **决策表测试法**
    - 由条件桩、行动桩、条件条目、行动条目、规则组成。
    - 设计步骤：分析条件和取值决定决策表类型、计算理论规则个数、列出行动桩、列出条件和行动条目并考虑特殊条目、完成测试用例设计、评审决策表和测试用例集。
6. **Use Case 法（场景法）**
    - 软件功能由基本流和备选流组成，基本流是正常业务流，备选流是非正常业务流。
    - 设计步骤：分析基本流和备选流、设计场景、生成逻辑测试用例、设计实际测试用例、评审测试用例集。
7. **正交实验法**
    - 利用正交拉丁方思想从全面试验点中选典型点设计测试用例，可减少测试工时费用。
    - 步骤：构造因子 - 状态表、加权筛选生成因素分析表、利用正交表构造测试数据集。正交表有行数、因素数、状态或水平数等概念。
8. **黑盒测试方法选择策略**
    - 优先考虑等价类划分，结合有效和无效等价类。
    - 必用边界值分析，变量逻辑关系强时结合决策表和因果图。
    - 用错误推测法补充测试用例。
    - 输入条件组合强时用因果图或决策表，并用边界值法补充。
    - 业务逻辑清晰的系统级测试考虑场景法，综合其他方法。
    - 参数配置类软件用正交试验法。

## 二、白盒测试技术

  

1. **白盒测试概念**
    - 把测试对象看作透明盒子，按程序内部逻辑测试，针对源代码，主要用于单元、集成及回归测试，也可用于系统测试。测试中需开发桩模块和驱动模块，应进行配置管理。
2. **逻辑覆盖测试法**
    - 语句覆盖：使程序每个可执行语句至少执行一次，覆盖较弱。
    - 判定覆盖：使程序每个判断的真假分支至少经历一次，无法确定判断内部条件错误。
    - 条件覆盖：使每个判断中每个条件的可能取值至少满足一次，不一定覆盖分支。
    - 判定 - 条件覆盖：判断条件所有可能取值至少满足一次且判断结果至少出现一次，存在条件掩盖问题。
    - 条件组合覆盖：使每个判断的所有条件取值组合至少执行一次，仅覆盖部分路径。
    - 路径覆盖：覆盖程序所有可能路径，实际难以实现，且不能保证程序正确性。基路径算法可压缩路径数，通过计算程序图环路复杂性确定独立路径数，按算法寻找基路径。
3. **程序插桩**
    - 在被测程序插入探针输出运行特征数据，分析内部行为特征，设计时考虑探测信息、探测点位置和数量。
4. **其他白盒测试方法简介**
    - 域测试：针对域错误，基于程序输入空间分析，有较多限制和弱点。
    - 符号测试：允许输入符号值，是程序测试和验证的折中，存在分支、二义性、大程序等问题。
5. **白盒测试方法选择策略**
    - 先静态后动态，静态进行结构分析、代码检查和质量度量，动态进行覆盖率测试。
    - 覆盖率测试重点是基路径测试法达语句覆盖标准，重点模块用多种覆盖率标准。
    - 单元测试侧重代码检查和逻辑覆盖，集成测试增加静态分析和度量，系统测试根据黑盒测试结果采取相应白盒测试。

# 第四章 单元测试总结

## 一、单元测试概述

  

1. **单元定义与测试对象**
    - 基本单元具有功能独立性等属性，结构化编程中单元指函数或子程序，面向对象编程中单元指类或相关类。单元测试是对最小单位的正确性检验，目的是发现内部错误或缺陷。
2. **测试步骤与执行者**
    - 包括人工静态检查（保证代码逻辑正确性等）和动态执行跟踪（通过测试用例比较实际与预期结果）。一般由程序员完成，测试部门可抽样测试和审核，必要时专门测试。
3. **测试目标与代码性质**
    - 目标是验证编码符合需求，确保单元正确性，同时检查代码质量、可复用性等。符合需求的代码应具备正确性、清晰性、规范性、一致性、高效性、可复用性等性质。

## 二、单元测试环境及过程

  

1. **单元测试环境**
    - 需辅助模块模拟接口，包括驱动模块（相当于主程序，负责接收数据、驱动被测单元等）和桩模块（代替被调子模块，配合父模块工作）。面向对象系统中以类或类内方法为测试单元，可为包或子系统设计驱动模块。设计时需考虑多种环境因素。
2. **单元测试过程**
    - 主要过程包括详细设计说明书评审、编制测试计划、开发测试用例、代码审查、测试用例评审、测试执行、缺陷提交与跟踪、测试报告及评审等，未通过需返回重新执行相关步骤。

## 三、单元测试策略

  

1. **传统结构化开发单元测试策略**
    - **自顶向下的单元测试**
        - 依据单元组件层次及调用关系，从顶层开始，将被顶层调用单元做成桩模块，逐层向下测试，上层单元测试时需开发驱动模块，下层单元需开发桩模块。优点是提供早期集成途径，与详细设计顺序一致可交叉进行；缺点是测试复杂、成本高，低层次结构覆盖率难保证，依赖顶层测试，并行性差，需求变更影响大。
    - **自底向上的单元测试**
        - 先测试最底层组件，模拟调用模块为驱动模块，逐层向上测试，上层单元测试需开发驱动模块和下层已测单元的桩模块。优点是底层测试功能明确，可早期集成，适用于详细设计文档缺结构细节情况；缺点是测试复杂、周期长、成本高，顶层结构覆盖率难保证，易受底层变更影响，并行性差，不能与详细设计和编码同步。
    - **孤立测试**
        - 不考虑单元组件间关系，单独设计桩和驱动模块测试每个单元。优点是简单易操作、测试时间短、覆盖率高、可并行测试；缺点是不能提供早期集成途径，增加额外测试成本。
2. **面向对象开发单元测试策略**
    - **一般类测试**
        - 目的是校验类是否按规格说明正确实现，由开发人员完成，测试代码视为程序一部分。数据设计考虑输入范围外数据、未考虑结果、系统错误等。类测试采用黑盒和白盒方法，根据类行为分为非模态类、单模态类、准模态类、模态类，测试原则包括方法、状态、状态转换、路径覆盖等。
    - **特殊类测试**
        - **抽象类测试**：因无具体实现，用已测类或创建桩实现后测试。
        - **泛型类测试**：建议先赋予简单经典类型参数，测试驱动器也采用泛型类。
    - **类测试的建议**
        - 执行类内所有方法，检查异常，确保类能到达所有状态，方法在各状态正确调用，保证状态转换正确，进行加载、性能等测试，用等价类和边界值法检查输入输出，子类测试注意扁平化、重定义方法用例设计和父类用例重执行。

## 四、单元测试的分析和用例设计

  

1. **一般单元测试分析**
    - 包括检查设计与代码一致性、分析功能与非功能需求、边界条件、错误情况、接口、数据结构、基路径与其他覆盖、出错处理正确性等，为相应测试设计服务。
2. **面向对象的单元测试分析**
    - **类的方法随机组合分析**：通过随机排列操作序列检查类实例生存史。
    - **类层次划分的分析**：分为基于状态、属性、类型的划分，减少相同方式检查用例数。
    - **类行为模型的分析**：用状态转换图导出类及合作类的动态行为测试序列。
3. **单元测试用例设计**
    - 先设计逻辑测试用例再设计物理测试用例，静态测试按要求完成工作，黑盒测试重点覆盖最小功能点，考虑非功能性需求和其他测试特性，从不同角度设计用例构成集合并评审，标识优先级、执行顺序、前提条件等，必要时补充非功能测试用例。

# 第五章 集成测试总结

## 一、集成测试概述

  

1. **定义与目的**
    - 集成测试是在单元测试基础上，将模块组装成子系统或系统，检验接口及集成后功能正确性，是对概要设计的验证，是单元测试的扩展延伸，使用对象为通过单元测试的单元。
2. **关注点**
    - 包括模块接口交互参数的一致性、单元测试未发现问题、子功能集成后父功能实现、新模块集成的负面影响、全局数据结构、特性误差、用户界面集成等方面。
3. **测试层次**
    - **传统结构化技术开发**：分为模块内集成、子系统内集成、子系统间集成、不同系统之间集成。
    - **面向对象技术开发**：分为类内集成、类间集成、子系统间集成、不同系统之间集成。

## 二、集成测试环境及过程

  

1. **测试环境**
    - 因系统而异，较单元测试环境复杂，受软件构件技术影响，可能需专业测试工具或开发接口模拟工具，搭建时考虑硬件、操作系统、数据库、网络、测试工具、开发驱动器和桩等环境因素。
2. **测试过程**
    - 划分为计划、用例分析和设计、实施、执行、分析评估阶段。
    - 计划阶段：在概要设计评审后进行，参考多文档制定，确定测试对象、范围、工作量、成本、组织结构、风险、资源、技术、缺陷处理流程、进出标准等。
    - 用例分析和设计阶段：在详细设计开始时进行，参考多文档，涉及集成对象结构、模块及接口、策略、方法工具、环境分析、用例设计评审、覆盖标准分析等活动。
    - 实施阶段：依据计划和用例集准备，包括搭建环境、选择调试工具、开发驱动器或桩、开发测试脚本、制定控制流。
    - 执行阶段：按计划集成顺序执行，单元测试完成且评审通过后进行，严格管理执行过程，记录结果，跟踪缺陷，按需回归测试。
    - 分析评估阶段：测试结束后召集相关人员，根据退出标准评估，产生测试分析和评估报告。

## 三、集成测试方法

  

1. **一般的集成测试方法**
    - **基于分解的集成方法**
        - 非增量式（大爆炸集成）：一次性集成所有单元测试通过的模块，优点是利用资源、用例少、方法简单，缺点是接口测试不充分、遗漏错误多、全局数据结构测试不彻底、错误定位难，适用于少数模块修改且前期稳定、功能少逻辑简单、净室软件工程开发的产品等情况。
        - 增量式（自顶向下集成、自底向上集成）
            - 自顶向下集成：按系统层次结构图，以主程序模块为中心自上而下组装测试，有深度优先和广度优先两种方式，优点是可早验证控制判断模块、深度优先可先实现软件功能、无需开发驱动器、开发测试可并行、故障隔离定位容易，缺点是桩模块开发维护成本高、底层模块需求变更影响大、底层模块测试不充分，适用于软件体系结构控制清晰等多种情况。
            - 自底向上集成：从最底层模块开始组装测试，优点是早验证下层模块、具有并行性、上层模块更多验证控制逻辑，缺点是最后才能见系统框架、驱动模块开发复杂、主控模块测试晚，适用于底层模块接口行为稳定等情况。
    - **三明治集成**：混合增量式方法，综合自顶向下和自底向上优点，桩和驱动器开发少，但最后集成阶段缺陷定位难，适用于大多数软件系统。
    - **基于调用图的集成**：包括成对集成（用实际代码代替桩 / 驱动器，关注调用图边对应的接口，减少桩和驱动器开发量）和相邻集成（根据模块节点邻居概念确定集成方式）。
    - **基于路径的集成**：涉及源节点、汇节点、模块执行路径、消息、MM 路径等概念，路径集成测试选择 MM 路径集合覆盖指标包括源汇节点路径、所有节点、消息调用和返回边。
    - **其他集成测试方法**
        - 分层集成：针对分层模型，不适用于层次间有拓扑网络关系的系统。
        - 基于功能的集成：按功能重要程度集成，能早实现关键功能，但不适用于复杂系统。
        - 高频集成：包括增量结束后编写测试包、形成新集成体测试、评价测试结果等步骤。
2. **面向对象的集成测试方法**
    - 目的是检查类或对象接口数据正确性，面向对象集成分三个类型（类的集成、子系统或组件的集成、层的集成），考虑五个层次（类的方法测试、消息序列、事件序列、线程测试、交互测试），覆盖指标包括类方法、消息、执行线程、ASF、类状态、对象调用关系等，分析和用例设计步骤包括选定类、确定覆盖指标、确定类关联、构造测试用例。

## 四、集成测试的分析和用例设计

  

1. **集成测试分析**
    - **体系结构分析**：关注体系结构与需求一致性、合理性、人机交互界面、系统要素及组织方式。
    - **类或模块及接口分析**
        - 接口划分：基于概要设计，确定系统、子系统、模块边界及各类接口。
        - 接口数据分析：对函数、消息、类接口等进行分析，考虑参数、消息域等多方面情况，直接设计测试用例。
2. **用例的设计**：综合考虑测试方法、系统接口、覆盖要求、测试时间等，从系统运行、正向测试、逆向测试、特殊需求、覆盖指标满足、补充等方面入手。

# 第六章 系统测试总结

## 一、系统测试概述

  

1. **定义与目的**
    - 系统测试是在系统投入运行前，对系统各元素组装并确认测试，确保软件与硬件、外设、网络等正常配合工作。测试类型多样，涉及功能及非功能方面，依据系统需求规约和分析规约，属于黑盒测试范畴，可运用白盒测试思想。

## 二、系统测试环境及过程

  

1. **系统测试环境**
    - 包括硬件环境（服务器、客户端、网络设备等）和软件环境（操作系统、数据库、工具软件等）。确定环境组成时考虑计算机数量、外设、服务器组件、网络环境、测试工具等；管理环境时设置管理员、记录文档、管理访问权限、做好备份恢复。
2. **系统测试过程**
    - 划分为计划、用例分析和设计、实施、执行、分析评估阶段。
    - 计划阶段：测试经理依据相关规约和项目计划制定，包括测试范围、环境、准则、技术方法、人员任务、缺陷管理等内容，分制定和评审阶段。
    - 用例分析和设计阶段：测试技术人员参考相关文档，分析业务、接口、功能、输入输出、状态转换、数据、非功能等，依结果设计用例达到覆盖指标。
    - 实施阶段：搭建环境、准备工具、开发测试及脚本、确定软件版本基线，可能涉及培训。
    - 执行阶段：执行用例、记录结果、跟踪修改问题，工具支撑的测试需脚本回放记录，遵循规程，必要时回归测试。
    - 分析评估阶段：相关人员评估形成报告，内容包括用例有效性、覆盖情况、缺陷跟踪解决情况。

## 三、系统测试类型

  

1. **功能测试**
    - 是系统测试基本工作，依据需求规格和分析说明书验证功能需求。测试人员需了解规约、掌握测试方法和经验。用例设计方法多样，编写要规范并评审，便于监控管理和回归测试。
2. **性能和压力测试**：系统测试重点，在第 8 章详细阐述。
3. **容量测试**
    - 面向数据，确定系统处理一定容量数据的能力。步骤包括分析数据源、构造大容量数据测试、比较结果确定瓶颈、优化后重复测试。
4. **安全性测试**
    - 检查系统防范非法侵入能力。涉及多层安全，测试方法有功能验证、漏洞扫描、模拟攻击，测试内容包括应用程序、操作系统、数据库、服务器、网络环境安全测试。
5. **恢复性测试**
    - 验证系统从故障中恢复能力，通过人为手段使系统故障，检测自动或人工恢复情况，分析恢复策略、程度、安全性、时间、性能等。
6. **备份测试**
    - 主要指数据库备份，测试系统备份及恢复能力，是恢复性测试一部分。
7. **健壮性测试**
    - 测试系统健壮性，设计人员需妥善处理异常。常用方法有故障插入测试、场景法、错误猜测法等。
8. **兼容性测试**
    - 验证软件与环境依赖程度，包括硬件、软件、数据、平台化软件兼容性测试和新旧系统数据迁移测试。
9. **可用性测试**
    - 让用户操作，观察记录。方法有认知预演、启发式评估、用户测试法，重点是系统功能、业务、帮助等。
10. **可安装性测试**

  

- 验证成功安装系统能力，注意安装人员、环境要求、过程、提示、错误、完整性、许可验证、升级和卸载测试等。

  

11. **用户文档测试**

  

- 用户文档包括操作手册、维护手册、在线帮助。测试内容包括操作手册准确性、维护手册描述、在线帮助服务。

## 四、系统测试的分析和用例设计

  

1. **系统级功能**
    - 包括正常和非正常功能，如 ATM 系统的取款、存款、查询功能及相关异常情况。分析后用场景法等设计用例保证功能全覆盖。
2. **系统的业务流**
    - 强调流，包括正常和非正常业务流（系统线索），如 ATM 系统的多种业务操作流程。分析后用场景法等设计用例覆盖所有业务流。
3. **系统级别的接口**
    - 涉及硬件、软件、人等接口，如 ATM 系统的用户与触摸屏、按键、银行卡插槽接口等。用例设计覆盖接口正常和非正常情况。
4. **系统级别的输入和输出**
    - 涉及外部输入输出，考虑不正常情况，如 ATM 系统的卡输入、存款放钞及吐钞、收据、屏幕显示等。测试分析后用例覆盖所有输入输出。
5. **系统级别的状态转换**
    - 以 ATM 系统状态图为例，验证状态图与系统实现一致性后设计用例达到状态或边覆盖。
6. **系统级别的数据**
    - 以 ERD 为依据，验证其与数据字典和数据库一致性后从测试角度分析。
7. **系统非功能特性**
    - 根据系统需求确定，如 ATM 系统的性能、安全性、兼容性需求，分析后设计测试用例。

# 第七章 验收测试总结

## 一、验收测试概述

  

1. **定义与目的**
    - 验收测试在软件开发结束后进行，验证软件功能、性能及其他特性是否符合用户要求，是客户或客户参与的系统级测试，包括多种类型，是客户评价软件质量的重要标准，能检测商品化软件品质并出具报告，α、β 测试用于发现最终用户可能发现的问题。
2. **主要测试内容**
    - 包括安装、功能、可靠性、安全性、性能、易用性、可移植性、可维护性、文档测试等，当发现的缺陷数量和严重程度符合预期且得到解决，α、β 测试完成并完善后，用户验收测试完成。

## 二、验收测试过程

  

1. **验收测试标准的确认**
    - 通过黑盒测试完成，需制定测试计划和过程，规定测试种类、进度、实施策略、用例分析设计方法和控制等，测试结果为软件是否满足需求说明要求。
2. **配置复审**
    - 目的是保证软件配置齐全有序，包含维护必需细节，承包方需提供可执行程序、源程序、配置脚本、测试程序或脚本等软件配置内容及多种开发和管理类文档。
3. **可执行程序的测试**
    - 在相关审核完成后进行，包括功能、性能等多方面测试，每种测试含目标、启动标准、活动、完成标准和度量，性能和压力测试范围限于高频度和时间要求苛刻的功能子集。

## 三、验收测试实例（以 ERP 系统为例）

  

1. **ERP 验收测试要点**
    - 验收测试对象涵盖程序、数据和文档，主体以用户企业或第三方测试为主，注意以需求规格说明和技术合同为准、以验证正确性为主、分级分类处理缺陷、用例设计全面多维高效，软件实施人员需配合用户做好准备、执行测试、分析评估结果、跟踪缺陷并确保通过验收。
2. **具体测试内容及用例设计注意事项**
    - **安装测试**：根据可移植性选不同操作系统，用不同软硬件配置测试，观察正常和资源不足时安装情况。
    - **功能测试**：输入域全面（含合法非法数据），划分等价类，利用边界值，重复递交事务，不按常规顺序操作，验证实体关系，观察异常输出。
    - **界面测试**：检查颜色、外观风格、布局、标题描述、操作一致性、显示比例格式、错误提示、高亮显示、帮助信息、特殊域和控件等。
    - **性能测试**：测试运行速度和资源消耗，调整多种因素并用自动化工具辅助，通过极限测试评估性能。
    - **文档测试**：明确验收标准，确定文档重要性和需求，检验完整性、一致性、准确性、可理解性。
    - **其他测试**：负载压力测试（包括多种类型，以真实业务为依据设计用例）、恢复测试（模拟故障检测数据破坏和恢复程度）、安全性测试（用多种方式检测安全防护策略）、兼容性测试（考察跨平台和可移植特性）。

# 第八章 负载压力测试总结

## 一、负载压力测试基础

  

1. **负载测试**
    - 逐步增加系统负载，确定满足性能指标时系统能承受的最大负载量，也可称为 “容量测试”“耐久性测试” 等，“零容量测试” 是加空任务进行测试。
2. **压力测试**
    - 逐步增加负载，确定系统性能失效的负载条件，获取最大承受能力级别，如测试页面响应时间超过规定值（如 1min）时的并发访问用户数量。
3. **性能测试**
    - 保证产品发布后系统性能满足用户需求，包括性能调优与性能评测两种策略，在软件质量保证中起重要作用。
4. **负载压力测试目的**
    - 在生产或真实环境测试系统性能，评估是否满足需求；预见系统负载承受力；分析系统瓶颈并优化。

## 二、负载压力测试策略

  

1. **手工测试**
    - 可通过多计算机和操作人员模拟负载压力，但需大量人员和设备，同步问题难解决，无法捕捉程序内部变化。
2. **自动化测试**
    - 利用商业化或开源测试工具，在一台或几台 PC 上模拟大量虚拟用户执行业务，可重复、真实地度量应用性能，确定问题所在。商业化工具知名且适用范围广，开源工具免费。

## 三、负载压力测试的解决方案和实施

  

1. **解决方案**
    - **客户端性能测试**：用负载压力测试工具模拟并发用户，含主控台、代理机和被测服务器，主控台管理代理和收集数据，代理模拟虚拟用户加压，可多代理单主控台。
    - **网络的性能测试**：包括网络应用性能监控和故障分析，可优化性能、预测响应时间、确定带宽需求、定位故障。
    - **服务器端的性能测试**：可采用工具自动监控或操作系统、数据库、中间件自带监控工具。操作系统监控后台服务器，数据库监控指标复杂多样，中间件资源使用和连接合理性影响系统性能。
2. **实施步骤**
    - **测试计划**：描述负载测试计划过程，包括分析应用程序（确定系统组件、描述配置、分析使用模型）、定义测试目标（制定度量目标和确定时间）、计划方案实施（定义性能度量范围、Vuser 活动、选择 Vuser 和软硬件）、分析测试目标（度量用户最终响应时间、考虑硬件配置、可靠性等）。
    - **测试分析**：需求分析需理论知识和经验积累，采用 80 - 20 原则估算测试强度。
    - **测试用例设计**：对比测试环境和真实业务环境，确定后考虑并发性能、疲劳强度、大数据量测试和系统资源监控等内容。
    - **测试环境、工具、数据准备**
        - 测试环境原则：模拟真实或满足最低要求后选真实环境，选用一致平台，营造独立无毒环境。负载压力测试强调真实环境，准备时要降低对业务影响、考虑工具配置要求、包含安装备份恢复过程，配置包括操作系统等版本信息，标准要满足技术要求和保证结果稳定可重复正确。
        - 测试工具选择：考虑模拟客户端、运行多客户端、脚本化执行编辑、支持会话、可配置用户数量等功能，也有缺乏功能点校验等局限性。
        - 测试协议选择：以客户端与直接压力承受服务器之间通信协议为标准。
        - 测试数据准备：准备业务测试数据，常需在真实环境表现。
    - **测试脚本开发与调试**：脚本可录制、编写或混合生成，经增强编辑后调试可用，处理动态数据时关注 Insert 及 Update 语句参数化。
    - **测试场景设计**：创建 Vuser 组、配置 Vuser 及其运行设置、配置负载生成器、终端服务、WAN 仿真和脚本。
    - **测试执行**：运行场景，执行时查看 Vuser，可使用联机监视工具，结果分析靠工具和工程师经验。
    - **获得测试结果**：Vuser 执行事务时生成结果数据，可监视场景。

## 四、负载压力测试结果分析

  

1. **交易处理性能分析**：评估指标包括并发用户数、交易响应时间、交易通过率。
2. **资源占用性能评估**
    - 服务器操作系统资源占用监控指标有 CPU、磁盘管理、内存、交换区、吞吐量、点击率、进程、安全控制、文件系统等。
    - 数据库资源占用监控指标涉及读写页面、缓冲区操作数、作业等待时间、日志缓冲区使用率、磁盘数据块、用户事务、锁资源、表空间增长、SQL 执行情况等。
    - 中间件资源占用监控包括 Web、应用、交易等中间件。
3. **故障分析**
    - 重点内容包括 CPU、应用程序、内存和高速缓存、磁盘（I/O）资源、配置参数、网络设置、数据库服务器故障定位等问题。优化调整设置，识别故障问题如处理执行错误、速度瓶颈、服务水平不达标、接口页面问题等，Web 网站故障可通过优化 ASP 代码、数据库调用、使用存储过程、调整服务器性能等解决。

## 五、系统性能调优

  

1. **网络级调优**：使用存储过程减少通信量，过滤数据减少传输，配置网络包大小，分析优化网络参数，隔离负载大的网络，限制大网络负载请求。
2. **操作系统级优化**：考虑系统 I/O（单个硬盘速度和总带宽）和物理内存（是否有大量页交换、数据库所需内存）。
3. **数据库服务器参数配置策略优化**
    - **内存管理**：内存足够时增大存储过程缓冲参数，增加物理内存扩大数据缓冲区，使用命名缓存。
    - **锁策略**：锁影响性能，优化锁级别，避免死锁，设置页级锁升级阀限，不在无意义 ID 上加聚簇索引。
    - **存储策略**：合理分配表分区、减少物理 I/O 次数、优化数据存储策略。
4. **数据库优化策略**
    - **表结构设计**：根据应用类型（OLTP 和 OLAP）选择规范化（如 3NF）或非规范化设计（增加冗余等）。
    - **数据划分**：分为当前和历史数据提升性能。
    - **阈值机制**：控制空间膨胀和预警。
    - **索引**：查询条件与索引配合提升 SQL 语句性能。
5. **应用级优化**：减少公用资源争用和磁盘 I/O，包括服务器或客户端处理选择、程序逻辑改写优化、事务设计优化、使用存储过程减少编译和传输时间。
6. **服务器端应用优化**：查询用索引、判断用 exists、表连接优化、避免 cursor、使用存储过程并适时重编译。
7. **客户端应用优化**：包括继承结构、事件、变量级优化、耦合处理和业务逻辑辅助工具。性能设计和调优需平衡多种因素。

# 第九章 APP 应用测试总结

## 一、移动操作系统介绍

  

1. **Android 系统**
    - 具有开源、自由度高但安全性低的特点，操作系统包括应用程序层（用 Java 编写，基于系统 API 构建）、应用程序框架层（开发者可访问 API 框架）、系统库（由 C/C++ 实现，提供功能服务）、Linux 内核（提供核心系统服务，隐藏硬件细节）四层。
2. **iOS 系统**
    - 具有出色触控体验、强大 App Store、高安全性及扩展性强的特点，系统架构分为可触摸层（负责触摸交互操作）、媒体层（提供视听技术）、核心服务层（提供基础系统服务，定义数据类型）、核心操作系统层（包含低级硬件功能）四层。

## 二、App 启动执行过程

  

1. **Android App**
    - 点击图标后，Launcher 通过 Binder 通信调用 system_server 进程中 AMS 服务的方法发起启动请求，system_server 向 Zygote 进程发送创建进程请求，Zygote 进程 fork 出 App 进程并执行相关方法初始化，App 进程通过 Binder 与 system_server 进程交互，最终主线程创建并回调相关方法。
2. **iOS App**
    - 点击图片执行 main 函数，调用 UIApplicationMain 创建相关对象，delegate 对象处理系统事件（无 storyboard 时）或根据 Info.plist 加载 storyboard（有 storyboard 时），包括创建和设置 UIWindow 及 rootViewController 并显示窗口。

## 三、App 项目开发流程

  

1. 需求调研与分析整合：确定需求定位、目标用户、开发平台等，评审修改完善需求规约文档。
2. 预算评估与计划：技术团队评估需求技术难度及可行性，制定时间安排计划。
3. 原型设计：依据需求设计功能布局、页面及业务逻辑，评审修改原型图。
4. UI 设计：进行配色、功能化处理、交互及适配设计，形成高保真设计图。
5. 开发：包括服务器端（环境架构、数据库和 API 接口设计）、App 端（界面开发与服务端接口对接）、Web 管理端（编写功能逻辑代码），可前后端分离并行开发。
6. 调试与测试：程序员调试修复，测试人员进行系统测试和验证测试。
7. 上线运行及总结：内部测试通过后上线，编写相关文档并培训运营人员。
8. 迭代与持续交付：根据用户反馈修正、增强功能，优化迭代版本并持续发布。

## 四、App 测试自动化及测试准备

  

1. **App 测试自动化**
    - 自动化可提高效率等，但不能取代手工测试，应结合使用。功能测试工具有 jmeter、UI Automator Viewer、Android Junit、Instrument 等，性能及其他测试工具如 MAT、WebView、ARC、Xcode 自带 Instrument、apacheAB、Jmeter 等，专项测试工具如 iOS 的 Network Link Conditioner 等。
2. **App 测试准备**
    - 制定测试计划（包括人员、时间、准则、环境、用例等安排），准备测试资源和环境（需求文档、原型图、设计图、设备、工具等），检查 App 测试版本是否符合入口条件。

## 五、App 功能测试

  

1. **UI 测试**
    - **导航测试**：关注按钮、对话框等导航切换，是否易于导航、需否搜索引擎、导航帮助准确性及与页面风格一致性。
    - **图形测试**：关注控件操作方式统一性、自适应界面、页面标签和图片风格、美观性、图片质量和尺寸、颜色使用。
    - **内容测试**：关注输入框说明文字与功能一致性、文字长度限制、表意、错别字、语言显示、敏感性词汇和图片。
2. **业务功能测试**
    - 依据需求规约，采用多种方法提炼功能场景，用黑盒、白盒及错误推测等方法设计用例，搭建环境执行用例并跟踪缺陷。
3. **其他功能测试**
    - **运行 App 测试**：关注安装后试运行、加载提示、启动速度、注册登录注销等功能的正常处理。
    - **应用的前后台切换测试**：关注切换后功能及状态正常性，包括锁屏解屏、电话呼入、杀掉进程、处理提示框等情况。
    - **免登录测试**：关注免登录功能与系统版本关系、无网络情况、切换用户、多设备登录、密码更换、自动登录及主动退出登录后的功能正常性。
    - **App 更新测试**：更新时关注更新提示、取消更新、强制更新、本地更新、意外情况处理，更新后关注功能与需求一致性及 UI 测试。
    - **离线浏览测试**：关注无网络及各种状态切换下能否正常浏览及服务端数据更新提示。
    - **数据更新测试**：根据业务规则确定更新方案，关注手动 / 自动刷新、前后台切换更新、实时 / 定时更新、数据处理逻辑及异常处理。
    - **定位服务测试**：用真机测试前后台切换、定位提示及跳转开启定位功能。
    - **时间影响测试**：校验手机时区时间设置对 App 显示时间和功能的影响。
    - **客户端数据库测试**：检查数据增删改查、表自动创建、数据同步更新、获取数据方式及本地保存情况。
4. **用户体验测试**
    - 通过用户访谈、内测、公测等方式，关注滥用引导、按钮状态、交互流程、点击范围、标签页关系、操作主次、返回逻辑、横屏模式等方面。

## 六、App 非功能测试

  

1. **安装、卸载测试**
    - **安装测试**：关注不同系统安装、安装后运行、安装选项组合、取消安装、意外情况处理、空间不足和断网提示、安装手册测试。
    - **卸载测试**：关注直接删除和系统卸载提示、文件删除情况、意外情况处理、取消卸载功能。
2. **安全测试**
    - **权限测试**：检测输入有效性、认证授权、敏感数据存储加密、手机功能使用限制、用户授权级别及数据泄漏风险。
    - **安装与卸载安全测试**：关注安装图标、数字签名、文件内容一致性、安装路径、自动启动、卸载安全、配置复原、对其他软件影响及文件移除。
    - **数据安全测试**：保证敏感数据加密传输、不存储在设备、不单独写明文、不忽略安全警告、不连接隐私信息、不损坏删除个人信息、重写数据时告知用户。
    - **通信安全测试**：关注通信或充电时程序暂停恢复、连接中断处理、通信延时中断异常通报、HTTP/HTTPS 覆盖测试及异常捕获。
    - **人机接口安全测试**：关注返回菜单可用性、命令优先权、其他设置影响、异常操作处理。
3. **性能测试**
    - **响应**：测试冷启动、热启动、完全启动、有网无网启动时间及业务场景导航页面切换响应时间。
    - **内存**：测试空闲、中强度、高强度状态内存消耗及退出页面或操作后内存回落和增长情况。
    - **CPU**：关注运行前后、空闲和高负荷时 CPU 占用率。
    - **FPS**：测量应用流畅度，Android 可用 adb 等工具，iOS 可用 instruments 测试。
    - **GPU 渲染**：关注过度绘制情况，不同颜色代表不同绘制程度。
    - **耗电量**：对比安装 App 前后待机功耗、常见场景和长时间使用时电量消耗，Android 可用 Emmagee、GT，iOS 可用 instruments 测试。
4. **兼容性测试**
    - 涉及屏幕分辨率、软件、硬件、网络兼容性问题，可通过统计 SDK 了解用户情况，购买设备和手机卡测试，辅助工具如 monkey、Appium 等。

## 七、App 专项测试

  

1. **相关特定操作测试**
    - 测试手机开锁屏、切换网络、前后台切换、多 App 切换、关机、重启、充电、kill 进程再打开对运行 App 的影响。
2. **弱网测试**
    - 关注无网络和弱网络下页面请求、数据返回、超时等情况的处理和提示。
3. **网络超时测试**
    - 可通过绑定未知服务器、主机绑定、绑定代理服务器、修改程序代码等方法实现测试。
4. **操作类型测试**
    - 根据 App 应用场景，如摄像头、横竖屏等，确定测试要点，如扫描拍摄角度、横竖屏切换等。
5. **交叉事件测试**
    - 测试 App 运行时其他事件或操作（如前后台切换、通信、使用设备等）对其正常功能的干扰。
6. **第三方推送测试**
    - 关注推送消息发送规则、用户接收设置（如免打扰）、推送与用户身份匹配等。
7. **消息推送测试**
    - 用真机测试推送消息是否按规则发送、用户接收设置有效性、推送与用户身份相符性。


# 第十章 微服务架构应用测试总结

## 一、微服务与测试

  

1. **微服务的由来**
    - 2014 年被提出，是一种架构模式，是面向服务型架构的变体，将单一应用划分为小服务，服务间通过轻量级通信机制（如 HTTP 的 RESTful API）协作，围绕业务构建，可独立部署，避免集中式管理，应根据业务选择合适技术构建。
2. **微服务与传统开发方式**
    - **单体式架构**
        - 优点：开发团队管理和进度管理简单，功能集中无分布式损耗。
        - 缺点：效率低、维护难、不灵活、稳定性差、扩展性不足。
    - **微服务架构**
        - 优点：部署回滚简便，可按需选择技术方案，服务可单独扩容，新功能添加灵活，可自主管理业务数据。
        - 缺点：系统内部通信需求和团队交流成本增加，测试复杂度提高，对 DevOps 能力要求高，服务管理复杂度随数量增加而指数级上升。
3. **微服务架构对测试人员意味着什么？**
    - 需考虑微服务拆分的必要性，避免盲目增加成本。微服务交互方式为契约测试提供基础，对 API 级别集成测试有新要求，服务测试不一定依赖 UI，微服务可进一步细分模块。

## 二、微服务对软件测试的挑战

  

1. **总体的测试策略**
    - 要全面测试微服务各层次，确保测试执行快捷以实现 CI/CD，树立质量第一思想，避免无意义测试，测试应交付高质量软件。
2. **传统测试方法面临的挑战**
    - 服务间依赖复杂，保证依赖正常是挑战。服务运行环境不同，需构建自动化部署体系。涉及多服务的 UI 端到端测试易出错，测试结果受网络稳定性影响（性能、可靠性、异步、数据一致性等方面），故障分析复杂度随服务增加而提高，与不同交付周期团队交流成本高。应对挑战可采取自动化、层次化（单元测试、服务测试、UI 测试）、可视化原则。

## 三、微服务架构的单元测试

  

1. **定义单元测试边界**
    - 准确定义测试边界，用 Stub 或 Mock 模拟外部依赖，单元测试可集成到代码合并流程，如 GitHub 可结合 CI 服务进行状态检查。
2. **单元测试的流程**
    - 分为设置测试数据、调用被测模块、判断结果三步（“三 A 原则”：Arrange、Act、Assert 或 Given、When、Then）。
3. **监控单元测试覆盖率**
    - 可使用 Teamcity 或 Jenkins 等工具结合 dotCover 统计覆盖率，并输出到 SonarQube 等代码质量监控工具。

## 四、微服务架构的集成测试

  

1. 目的是检查单元间协作、通信和接口，主要包括微服务对外模块与外部服务通信、数据库访问模块与数据库交互。
2. 实现手段有使用实际外部依赖服务、模拟器模拟外部服务（如 WireMock、mountebank）、网络故障模拟工具（如 clumsy）模拟不稳定网络条件。

## 五、微服务架构的组件测试

  

1. 组件指可独立工作的部分，微服务架构中即微服务本身。组件测试从服务外部 “用户” 角度审视服务功能和行为，与单元测试、集成测试侧重点不同。
2. 实施方法有单进程单服务测试（将模拟器等加载到同一进程，需修改源代码，执行速度快但有局限性）和多进程单服务测试（可验证网络配置，难点在于执行外部模拟器任务，适用于复杂集成等情况，可采用服务虚拟化工具）。
3. 对于前后端分离的前端微服务测试，模拟服务器提供静态内容，前后端开发独立，但集成时需确定契约并进行相关测试。结合单元、集成、组件测试可提高微服务测试覆盖率。

## 六、微服务架构的契约测试

  

1. 传统测试方法验证服务间协作成本高、结果不稳定、反馈周期长。契约是服务消费者与提供者协作的规约，包括请求、响应、元数据。契约测试基于契约验证协作，常用消费者驱动的契约测试（CDC）。
2. CDC 核心流程包括验证消费者业务逻辑并记录契约，用契约回放验证提供者。其核心原则是以消费者契约约束提供者，验证服务是否满足契约，不深入检查功能但关注输入输出数据结构等。常用 CDC 测试框架有 Janus、Pact 等，以 Pact 为例介绍了其工作流程（生成契约文件和验证提供者）。

## 七、微服务架构的端到端测试

  

1. **实施方法**
    - 以网页端为例，介绍了多个端到端测试框架，如 Protractor（通过编写配置和测试用例，调用相关组件启动浏览器执行测试，具有模拟用户操作、支持多种元素、智能等待、方便管理 WebDriver 等功能）。
2. **优化措施**
    - 测试应简洁，覆盖核心路径；谨慎选择测试范围；通过自动化部署提高测试环境可重复性；摆脱数据影响（新建数据）；利用 Protractor 的 Page - Object 概念减少重复代码和维护工作量。

## 八、微服务架构的云端测试和性能测试

  

1. **微服务的云端测试**
    - 包括本地测试云端应用程序和用云端测试机器测试本地或云端应用程序。本地与云端测试在登录机制和网络状态上有区别，本地测试云端应用需考虑登录差异、模拟网络故障、使用监控工具。测试即服务（TaaS）具有节约环境配置时间等优点，云测试类型包括功能测试（系统验证、用户验收、互操作性测试）和非功能性测试（可用性、用户划分、性能、安全、灾难恢复、可扩展性测试）。
2. **微服务的性能测试**
    - 是微服务测试重要部分，包括多种类型，可证明系统性能指标并找出性能下降原因。总体流程包括确定测试环境、验收标准、计划设计方案、配置环境、构建负载模拟测试体系（含客户端、测试控制器、测试代理）、部署方案、执行测试和分析结果。

## 九、微服务架构的测试流水线

  

1. **CI/CD**
    - 持续集成是提交新代码后构建、测试以确定能否正确集成，持续交付在持续集成基础上部署到类生产环境，持续部署进一步自动化部署到生产环境，目标是随时可交付和部署。
2. **自动测试流水线**
    - 常见测试流水线包含多个测试阶段，主流 CI/CD 自动化调度工具有 TeamCity（商业软件，安装配置简便）和 Jenkins（开源，适用于多种项目，兼容多种版本控制系统），并对比了两者特性。

## 十、DevOps 与测试

  

1. **DevOps 的出现**
    - 是软件工程文化和实践，统一软件开发和运维，特点是贯穿各环节的自动化和监控管理，目标是缩短周期、增加部署频率、可靠发布并结合业务目标。微服务架构下主流工作流程涉及开发、CI/CD、测试、部署等环节，DevOps 是完整的 IT 运维工作流。
2. **DevOps 在技术领域的实践**
    - **内建质量体系**：包括 TDD、结对编程和代码审查、自动化测试等实践。
    - **持续部署**：引入持续部署，采用蓝绿部署和金丝雀发布等实践。
    - **持续监控**：包括监控预警、日志聚合、分析等实践。
    - **度量与反馈**：涵盖持续集成、测试、运营数据反馈等实践。
    - **环境管理**：包括弹性架构、自动化部署脚本、基础设施即代码等实践。
    - **松耦合架构**：采用弹性基础设施、构建服务应用、引入契约测试等实践。
3. **DevOps 使用的主流工具**
    - 涉及版本控制、自动化构建测试、持续集成交付、容器平台、配置管理、微服务平台、服务开通、日志管理、监控警告分析等多方面工具。
4. **从 DevOps 到 TestOps**
    - TestOps 是 “测试运维”，推动研发与发布体系融合，工作内容包括搭建维护持续集成工具、编写维护配置中心代码、处理维护服务、进行产品测试等，与 DevOps 构成完整体系，TestOps 人员需具备 Dev、Ops、Test 能力。


# 第十一章 嵌入式系统测试总结

## 一、嵌入式系统介绍及测试基础

  

1. **嵌入式系统与嵌入式操作系统**
    - 嵌入式系统是以嵌入式计算机为核心，软硬件可裁减，满足多种严格要求的专用计算机系统。嵌入式操作系统负责资源分配等，具备多种基本功能，还具有可装卸性、强实时性、统一接口、操作方便、网络功能强、稳定性高、硬件适应性好等特点。常用的有 Palm OS（32 位，节能、内存管理好，数据存储格式特殊）、Windows CE（开放、模块化、实时性好、通信强，支持多种 CPU）、Linux（内核精简、跨平台、工具丰富、中文支持好等）。Linux 开源且内核小效率高，跨平台，注释文档全；Palm OS 有开放接口，Windows CE 相对臃肿。
2. **嵌入式测试方法概要**
    - 嵌入式软件测试目的是满足需求规格，在单元、软件集成、硬件 / 软件集成、系统集成四个阶段进行，后一阶段特有的硬件 / 软件集成测试验证软件与硬件交互。测试方式有白盒（常通过硬件仿真在开发环境进行）和黑盒（依据预期用途，重要方面是极限测试）。测试环境有目标环境（测试全面但昂贵耗时）和宿主环境（可进行部分测试，无法完全模拟目标环境），常需折中选择。

## 二、嵌入式测试策略

  

1. 不建议所有测试都在目标上进行，原因包括与开发者争时间、目标环境不可行或不便、昂贵且影响现有应用。
2. **不同测试阶段策略**
    - **单元测试**：主机环境进行，目标环境确认一致性。
    - **集成测试**：主机环境模拟目标环境完成软件集成，目标环境重复测试确定环境问题。
    - **系统测试和确认测试**：必须在目标环境执行，包括多种测试内容。
3. **嵌入式系统测试策略步骤**
    - 主机环境用测试工具插装进行静态测试，执行源码功能测试并修正错误，用插装代码执行覆盖率测试并优化，目标环境重复功能测试确认正确性，必要时重复覆盖率测试。
4. **其他建议**
    - 使用工具，尽早发现内存问题（内存泄漏、碎片、崩溃，可用相应工具排查），关注代码优化，重现隔离问题，用版本控制工具，确定测试完整性（白盒覆盖测试可评估），提高代码质量节省时间。

## 三、嵌入式测试环境的创建与实施

  

1. 开发过程分模拟、原型、临近生产、开发后阶段，各阶段有特定测试环境和目标。
2. **模拟阶段**
    - 基于模型开发，创建仿真模型支持设计等，测试目标是验证概念和优化设计，包括单向模拟（注入单输入分析输出，忽略动态交互）、反馈模拟（测试系统与环境交互）、快速原型法（用真实环境测试仿真系统）。
3. **原型阶段**
    - 目标是证明仿真模型有效性、确认系统满足需求、临近生产单元发布。模拟部件被硬件和软件替代，用仿真器模拟，涉及软件单元与集成、硬件 / 软件集成、系统集成、环境测试，环境测试检验系统对环境影响和敏感性。
4. **临近生产阶段**
    - 建造生产前单元校验需求满足度等，测试目标包括校验需求、论证标准符合度、生产和维护可行性、向客户演示。测试类型有系统验收、质量鉴定等，方法有实际情况、随机、故障引入测试。
5. **开发后阶段**
    - 采取生产设备开发测试、首件产品检查、生产和维护测试等措施保证生产质量。

## 四、嵌入式测试的工具

  

1. 源码级调试器：提供单步调试等功能，是基本调试方法。
2. 打印显示工具（如 printf）：灵活简单，可查看代码执行情况。
3. ICE 或 JTAG 调试器：仿真 CPU 核心，实时检测内部工作。
4. ROM 监视器：驻留 ROM，与工作站调试软件通信。
5. Data 监视器：不停止 CPU 运行显示变量内容及变化。
6. OS 监视器：显示任务切换等事件。
7. 性能分析工具：检测系统瓶颈和 CPU 使用情况。
8. 内存测试工具：查找内存问题。
9. 运行跟踪器：显示 CPU 函数执行情况，发现异常。
10. 覆盖工具：显示执行代码和未执行分支，助于优化代码。
11. GUI 测试工具：在开发环境运行测试用例，有记录回放等功能。
12. 自制工具：为特定目的编写，如视频流显示工具助于找 bug。

# 第十二章 游戏测试总结

## 一、游戏测试基本概念

  

1. **游戏开发**
    - 游戏成功需具备 Vision（对游戏的前瞻性理解与策略考量）、Technology（实现 Vision 的技术）、Process（复杂且相互影响的开发过程，影响产品质量）。游戏软件与通用软件开发不同，需求存在理想化且变化快，开发阶段包括游戏策划、设计、编辑器设计、关卡设计等，常迭代开发并伴随测试。
2. **游戏测试与开发过程的关系**
    - 游戏开发过程是特殊软件过程，测试与开发同步进行，各阶段测试参与可提高对问题判断的准确性。

## 二、游戏测试的主要内容

  

1. 虽开发阶段不同，但测试贯穿游戏开发各阶段，包括静态评审和动态运行测试。游戏测试分为传统软件测试和游戏本身测试，具有游戏情节、世界平衡、文化测试等特性，可玩性测试是核心（本质为功能性测试），还包括性能、压力测试等。
2. 游戏软件测试涵盖基本功能（任务）、虚拟世界搭建（含交互平台及情节测试）、风格界面、性能压力测试等。测试可玩性的方式有内部测试人员分析、外部游戏媒体人员测试、外部玩家测试、内测公测等。

## 三、游戏测试的实施

  

1. **游戏策划与测试计划**
    - 测试计划明确测试目标、资源、进度等，源于策划书。包括程序功能、可玩性、性能测试计划，写明测试方法及是否用自动化工具，为测试打基础。
2. **游戏测试用例设计**
    - 测试方法有黑盒（高端，操作层面，可找不了解游戏玩家进行）和白盒（低端，需开发人员完成）。游戏测试分单元、集成、系统、验收测试阶段，可裁剪。用例设计依据有 UML 用例图、时序图、状态图及详细任务和情节说明书等，系统测试阶段可整理优化前期用例，考虑非功能性特性测试，场景法在系统测试中有用，创建场景方法包括分析对象生命历程等多方面。
3. **游戏性能测试**
    - 涉及客户端、网络、服务器端性能测试，在系统集成测试完成或接近完成时进行，优化先考虑数据库或网络配制，性能测试与优化需前期规划，不同架构网络游戏（C/S、B/S、缺陷网络游戏）性能测试实施方法不同。
4. **用例执行和测试报告**
    - 游戏测试用例模板与其他软件测试类似，执行时记录结果、时间、问题、版本号等，测试报告格式因企业而异。

# 第十三章 软件测试管理总结

## 一、测试计划的制定与估算

  

1. 软件测试计划是测试项目成功的前提，包括总体、单元、集成、系统等测试计划，应在项目总体测试计划框架下制定。测试工作量估算需进行 WBS 分解，根据经验和历史数据确定任务工作量，结合企业生产率估算成本，单位为人月数或人天数。

## 二、测试的组织

  

1. **组织结构选择因素**
    - 考虑垂直或平缓（平缓效率高）、市场或产品、集中或分散（测试组织应相对集中）、分级或分散、专业人员或工作人员、功能或非功能或项目等因素。
2. **结合实际选择组织方案**
    - 常见组织方式有基于技能（测试人员专注专业领域，需掌握专业工具和技术）和基于项目（利于模块协调集成）。选择准则包括利于决策、沟通合作、独立运作、协调关系、满足管理要求、利于技术实施和资源利用、调整计划及对人员产生积极影响等。
3. **测试组织的独立性**
    - 独立测试可避免开发者测试自己软件的弊端，具有客观性、专业性、权威性，能保证资源投入，对提高测试有效性意义重大。
4. **测试人员**
    - 包括测试管理者（负责测试项目，具备多种管理能力）和测试技术人员（需具备一般能力、测试技能、协助规划、执行、分析报告改进等能力）。测试人员需要激励机制，测试培训内容多样，培训计划应关注多方面，如纳入测试计划、管理层重视、明确目的、提前安排、注重实践、团队协作、评价改进等。

## 三、测试过程监控

  

1. 采用周报、问讯及查阅文档结合，对关键点抽样审核询问核实的方法监控测试工作。监控过程包括了解、发现、核实、评估、给出方案、解决问题，监控目的是解决问题降低风险。测试过程监控分测试初始期（重点监控测试计划制定和范围确定）、测试实施期（关注测试过程执行、范围遗漏、资源到位、文档更新、评审、缺陷管理和配置管理等）、测试结束期（评估产品质量，关注缺陷趋势、发布材料、退出条件满足情况）三个阶段。

## 四、测试文档

  

1. 软件测试文档是软件工程文档重要部分，包括测试计划、方案、用例、报告文档。测试计划文档包含测试范围、目的、方法、标准、资源、进度等内容，编写应及早开始；测试方案文档指明测试设计细节；测试用例文档决定测试效率，包含测试项目、编号、级别、步骤、输入输出值等；测试报告文档指明测试结果，包含测试时间、人员、产品、版本、环境、问题、结果统计评价等。

## 五、软件配置管理

  

1. **配置管理简介**
    - 配置管理对软件配置标识并控制更改，保证完整性和可溯性。相关术语有配置项（包括产品组成部分和管理文档，有名称、标识符等属性）、基线（配置项受控状态，是下一步开发基准）、版本（标识配置项功能，随功能变化而演变）。配置管理工作包括识别配置项、建立系统、建立基线、状态报告、审计和变更控制管理。
2. **测试配置管理**
    - 目标包括控制审计变更、建立基线、记录跟踪请求、确保测试活动和产品可用。承诺涵盖明确责任、贯穿测试活动、应用于配置项、建立库、定期评审。纳入管理的项有测试计划、用例、报告、工具、合同、被测软件资源、文档模板和数据等。测试过程角色和活动涉及测试计划、设计、实施、评估阶段，各阶段有不同角色、输入和输出，配置项状态有草稿、正式发布、正在修改三种，变迁规则明确。测试配置管理步骤包括标识创建配置库、分配权限、制定流程、控制变更、管理基线、清除备份文件、指定标识，变更配置项需遵循申请、审批、安排任务、执行、评审、结束变更的流程。

## 六、测试与风险

  

1. **项目风险**
    - 软件项目风险影响项目计划实现，可分为项目管理、技术或质量、商业、战略风险。风险管理包括风险识别（持续过程）、应对计划制定（依据风险优先级处理）、应对策略（规避、转移、降低、接受）、监控（应对风险并更新计划）。风险跟踪确保项目计划完成。
2. **软件测试风险**
    - 测试风险源于测试计划不充分等，导致测试不足和结果不准确，交付潜藏问题。计划风险包括进度、需求、范围、资源等方面，交付日期风险是主要风险之一。应对措施有增加资源、缩小范围、减少质量过程等，需提前制定应对计划，软件风险分析与测试计划风险分析相辅相成。风险应对措施包括避免（如检查测试环境）、转移（如去除严重 bug 功能）、降低（如提高测试用例覆盖率）风险，需做好风险管理计划和应对缓解计划并跟踪管理。

## 七、缺陷管理

  

1. **软件缺陷的属性描述**
    - 缺陷管理确保缺陷及时处理，缺陷属性包括标识（唯一标记）、类型（如功能、赋值等）、严重程度（影响软件产品程度，分严重、较大、较小、轻微、其他缺陷）、优先级（修复紧急程度，分立即解决、正常排队、不紧急）、状态（跟踪修复进展，如提交、接受、分配等）、起源（检测阶段，如需求、架构等阶段）、来源（所在地方，如文档、代码）、原因（错误根本因素）。
2. **软件缺陷管理流程**
    - 包括发现提交、分析定位、提请修改、修改、验证修改缺陷，项目组记录、监控、验证缺陷修改过程。
3. **软件缺陷度量**
    - 缺陷度量生成统计图表，如缺陷类型分布（分析关键类型及根源制定改进措施，如接口缺陷的原因及改进建议）和缺陷收敛趋势分析（通过缺陷数趋势图表确保项目健康发展，分析波动原因，判断版本外发依据，需稳定研发过程保证数据可信度）。
4. **缺陷跟踪管理系统**
    - 核心是缺陷报告，包括操作 / 再现步骤（准确描述重现缺陷，是修复向导）、期望结果（与测试标准等一致，提供验证依据）、实际结果（确认缺陷问题及影响要素）。好的报告避免重复，提供必要信息。常见缺陷跟踪管理软件有 Bugzilla、Mantis、TestDirector 等，也可自行开发。


# 第十四章 软件测试工具总结

## 一、测试工具的类型

  

1. **测试管理工具**
    - 管理整个测试过程，包括管理软件需求、测试计划、用例、缺陷跟踪及数据统计汇总。主流工具有 TestCenter、QMetry 等。
2. **静态测试工具**
    - 直接分析代码，无需运行或编译。包括评审过程支持工具（记录评审信息、管理流程等）和静态分析工具（分析数据流和控制流找缺陷、评价代码质量），可发现多种代码缺陷。代表有 SonarQube、cpplint 等。
3. **功能测试执行工具**
    - 用于回归测试，保证测试完整性和全面性，缩短时间，多在系统测试阶段用于图形用户界面应用程序。功能有录制和回放、检验、可编程，使用过程包括准备录制、录制、编辑脚本、调试、运行测试、分析结果报告问题。主流工具有 Selenium、Appium 等。
4. **覆盖工具（结构性测试工具）**
    - 帮助解决手工测试难以检测全部代码功能的问题，衡量和跟踪代码执行及稳定性，依据逻辑结构设计测试用例，用逻辑覆盖率衡量测试完整性，可统计覆盖率并定位未覆盖逻辑。商业性工具有 Numega 系列等，非商业性工具有 Junit、Cppunit 等。
5. **性能和压力测试工具**
    - 性能测试工具模拟运行环境，检验性能指标，分析问题和瓶颈，新一代可无人值守运行，支持虚拟用户测试。压力测试工具让客户端高压力运行观察崩溃情况，暴露多种缺陷。主流工具有 LoadRunner、Load impact 等。
6. **其他工具**
    - **测试设计工具**：帮助设计测试用例，分为基于程序代码（白盒工具，分析代码结构产生输入数据，用于单元测试，有局限性但便利）和基于需求说明（生成完整测试用例，需转化需求格式，适用于各种系统）两类。
    - **嵌入式测试工具**：贯穿嵌入式软件开发各阶段，面向源代码工作，有诸多好处，如查找错误、定位缺陷模块、改进实践等。还有数据库测试的 TestBytes、性能优化的 EcoScope 等工具。

## 二、测试工具的选择

  

1. 考虑工具功能（结合项目特点，关注实用性和侧重点）、价格因素（视企业财政状况）、综合评估（确定企业期望、评估工具性能、总结试用结果）以及引入目的（考虑连续性和一致性，可关注开源工具集成）。

## 三、测试自动化与手工测试

  

1. **手动测试的不足**
    - 测试人员文档工作繁重，受多种因素限制难以全面测试，回归测试困难，缺陷管理缺乏有效手段，测试标准易不一致，多用户测试不便，难以测试不可视对象属性。
2. **自动测试的优点**
    - 能完成手工难或不可能的测试（如并发操作测试），提高测试效率（多次重复执行）、准确性（降低人员技术要求），可无人照料测试，具有一致性和可重复性，利于回归测试，缩短测试时间。
3. **自动测试的局限性**
    - 可能降低少量测试时的效率，再次运行发现错误概率低（除非代码修改或环境变化），测试组织差等情况时发现错误能力差，存在技术问题（如工具与其他软件互操作性），不能完全替代手工测试，测试人员需具备脚本开发等技能。
