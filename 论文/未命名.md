# 基于联邦学习和蒙特卡洛树搜索的多医疗机构乳腺癌生存状态预测合作研究

  

**作者**：Qi Chang、Lin Fan、You Wu、Yihui He  
**单位**：西南石油大学计算机科学与软件工程学院、成都理工大学管理科学学院

## 摘要

  

近年来，乳腺癌已成为全球女性健康的主要威胁，其发病率随着生活方式的改变和社会老龄化而显著上升。据世界卫生组织 2024 年发布的数据，乳腺癌已超过肺癌成为全球最常见的恶性肿瘤。在中国，乳腺癌发病率以每年 3% - 4% 的速度持续增长，这对乳腺癌的早期诊断、治疗方案优化和生存预测提出了更高要求。机器学习技术的蓬勃发展为乳腺癌生存预测带来了新机遇，但在多机构合作背景下，数据隐私保护成为亟待解决的重要问题。本研究聚焦于此挑战，创新性地引入联邦学习（FL）范式，使多个机构能够在不泄露本地数据隐私的情况下进行协同模型训练，有效打破了数据孤岛现象。同时，运用蒙特卡洛树搜索（MCTS）算法深入分析生存状态转移路径，为医疗决策提供更有价值的参考依据。针对数据不平衡问题，采用 SMOTE 技术对数据集进行预处理，确保模型训练的有效性。利用混淆矩阵和 ROC 曲线对分类模型性能进行综合评估。实验结果表明，该方法在预测准确性和可解释性方面具有优势，为乳腺癌研究提供了新视角。

  

**关键词**：多机构合作；乳腺癌生存预测；联邦学习；蒙特卡洛树搜索

## 一、引言

  

根据世界卫生组织（WHO）2024 年的统计数据，乳腺癌已成为全球发病率最高的恶性肿瘤，其快速增长对全球女性健康构成重大威胁。尤其在中国，乳腺癌年发病率以每年 3% - 4% 的速度递增，预计未来几年防控形势将更加严峻。这一趋势对乳腺癌的早期诊断、个性化治疗和生存状态预测提出了更高要求。近年来，机器学习技术因其强大的数据处理和模式识别能力，在医疗领域展现出巨大的应用潜力，尤其有望在乳腺癌生存预测中发挥关键作用。在实际医疗场景中，多个医疗机构积累了丰富的乳腺癌患者数据。然而，由于法律法规和数据安全等因素限制，这些数据往往处于孤岛状态，无法直接整合用于模型训练。传统的集中式机器学习方法在这种情况下难以应用，因为它们需要集中存储和处理数据，这不仅侵犯患者隐私，还存在数据泄露风险。联邦学习的出现为解决这一困境提供了有效途径。作为一种先进的分布式机器学习框架，联邦学习允许每个医疗机构保留数据的本地所有权，同时共同参与模型训练。通过联邦平均算法等安全参数聚合机制，每个机构只需上传模型参数的更新部分，无需共享原始数据，从而确保数据隐私得到严格保护。通过这种协作方式，各医疗机构的数据资源能够得到充分利用，模型的泛化能力将得到提高，促进医疗知识的共享和交流，推动整个医疗行业的发展。

  

然而，仅提高模型的预测准确性是不够的，模型的可解释性也非常重要。在医疗决策中，医生需要了解模型预测的依据才能做出合理判断。蒙特卡洛树搜索（MCTS）是一种基于随机模拟和搜索树的强大计算方法，能够模拟生存状态转移过程，揭示不同状态之间的潜在关系，为模型预测提供直观的解释路径。通过 MCTS 分析，医生可以深入了解疾病发展的可能趋势，从而制定更准确的治疗策略。

  

在本研究中，我们精心模拟了多个医疗机构合作预测乳腺癌生存状态的实际场景。为处理数据集中的类别不平衡问题，采用 SMOTE（合成少数类过采样技术）对数据集进行预处理，平衡不同生存状态的样本比例，提高模型对少数类样本的学习能力。构建分类模型，并利用混淆矩阵和 ROC 曲线（受试者工作特征曲线）对模型性能进行全面、严格的评估。实验结果表明，这种融合联邦学习与蒙特卡洛树搜索的方法在预测准确性和可解释性方面具有显著优势，为乳腺癌生存预测研究提供了新视角和有前途的研究方向。

  

本文的主要贡献如下：模拟多个医疗机构，使用 FL 方法，利用 SMOTE 对数据进行预处理以平衡数据集，并共同训练用于预测乳腺癌生存的全球模型；使用 MCTS 算法深入模拟乳腺癌生存状态的转移过程，准确揭示不同状态之间隐藏的内部联系，为模型预测结果提供直观清晰的解释；利用混淆矩阵和 ROC 曲线全面细致地评估模型性能，从多个关键指标综合衡量模型的优缺点。实验结果有力地证明了 FL 和 MCTS 在多医疗机构乳腺癌生存状态协同预测中的巨大应用潜力。

## 二、相关工作

### （一）联邦学习

  

联邦学习是一种专注于隐私保护的分布式机器学习技术。它允许参与者通过安全的参数交换机制在不共享本地数据的情况下协同构建全局模型。其核心特点是数据的本地存储和计算，避免了数据隐私泄露的风险。FedAvg 是一种经典的联邦学习算法，通过对客户端本地上传的模型参数进行加权平均来更新全局模型。然而，联邦学习在实际应用中面临两大挑战：一是非独立同分布（non-IID）数据可能导致全局模型偏向某些客户端数据；二是设备异构性可能降低算法的稳定性和效率。因此，提出了诸如 FedProx 和 SCAFFOLD 等改进算法。它们通过添加约束或控制变量在缓解上述问题方面相当有效，同时也提高了模型的训练性能。针对这些挑战，FedProx 算法得以开发，成功解决了联邦学习中遇到的各种困难。得益于 FedProx，不同设备可以根据自身实际情况进行不同次数的本地迭代训练，从而更好地适应设备异构性。此外，FedProx 引入的近端项有效地稳定了训练方法，增强了模型训练过程的稳定性。相比之下，传统的 FedAvg 算法在实践中容易受到梯度差异的严重干扰，尤其是在数据分布不均匀时表现不佳。为此，SCAFFOLD 算法通过巧妙利用控制变量成功克服了这一困难。有了 SCAFFOLD，数据的非 IID 特性和客户端采样问题不再对模型训练构成重大障碍。该算法可以在较少的通信轮数内达到预期的训练效果，显著提高训练效率。此外，FedNova 是一种先进的联邦学习算法，在保持快速误差收敛的同时有效消除了目标不一致的问题。FedNova 通过允许异构本地进度，对通信和计算变量表现出良好的鲁棒性和适应性。它通过使用校正后的模型聚合方案适当处理本地训练数据的大小和分布偏差，进一步优化了联邦学习模型的训练效果。

## 三、蒙特卡洛树搜索

  

蒙特卡洛树搜索算法是一种基于随机模拟和搜索树构建的强大决策算法，在许多领域尤其是人工智能和决策优化中发挥着重要作用。MCTS 算法的核心过程主要包括四个关键步骤：选择、扩展、模拟和回传。在选择阶段，算法从根节点开始，根据特定策略（如 UCT 公式）遍历搜索树，挑选出最有希望的子节点进行深入探索。UCT 公式兼顾节点的值和探索因子，以平衡对已知高价值节点的利用和对未充分探索节点的探索，引导搜索朝着更有希望的方向进行。当到达叶节点时，如果叶节点满足一定条件，则进入扩展阶段。在这个阶段，算法根据可能的动作或状态转换生成新的子节点，从而扩大搜索树的范围，增加决策空间的覆盖范围。扩展完成后，进入模拟阶段。从新扩展的叶节点开始，算法根据预定义的随机策略模拟一系列后续状态转换，直到达到终止条件。在模拟过程中，记录所经历的奖励或值，以评估模拟路径的优劣。最后，在回传阶段，算法从模拟结束的叶节点回溯到根节点，沿途更新每个节点的访问次数和累计值。通过这种方式，算法将从模拟中获得的信息反馈给搜索树，使树中每个节点的统计信息不断更新，为后续选择阶段的决策提供更准确的依据。MCTS 算法在不同领域表现出优异的性能和广泛的适用性。例如，在围棋和国际象棋等棋类游戏领域，MCTS 可以不断模拟游戏的发展，评估不同走法策略的优劣，从而在复杂的决策空间中找到最佳走法策略，并取得了显著成果，击败了许多传统算法。在机器人路径规划中，MCTS 可以根据环境信息模拟机器人的各种运动路径，考虑路径长度和障碍物等因素，找到最优或接近最优的运动路线，使机器人的运动更加高效和安全。在优化问题求解中，MCTS 可以快速搜索庞大的解空间，找到满足特定条件的最优或次优解，为解决复杂优化问题提供了有效方法。其强大的决策能力和适应性使 MCTS 算法在许多领域具有重要的研究价值和应用前景。

## 四、方法论

### （一）联邦学习

  

联邦学习作为一种先进的分布式机器学习技术，已被广泛用于有效打破数据孤岛困境。通过联邦学习，多个参与者可以在不共享原始数据的情况下协同构建强大的机器学习模型，从而在保护隐私的同时提高模型性能。图 1 展示了联邦学习的基本示意图。传统的集中式机器学习方法要求所有数据集中在服务器端进行模型训练和预测。然而，这种方法存在许多问题。首先，将数据上传到服务器容易导致隐私风险，数据泄露的后果可能非常严重。其次，集中式训练导致终端设备的计算能力未得到充分利用，是对资源的严重浪费。相比之下，联邦学习在隐私保护方面具有显著优势。参与联邦学习的客户端不需要与服务器或其他客户端共享数据。例如，在经典的 FedAvg（联邦平均）算法中，在每一轮训练中，服务器首先将当前的全局模型参数分发给每个客户端。客户端然后使用其本地数据训练模型，并将更新后的本地模型参数发送回服务器。最后，服务器通过计算所有本地模型参数的加权平均值来更新全局模型参数，这些参数将作为下一轮训练的基础。

### （二）蒙特卡洛树搜索

  

蒙特卡洛树搜索是一种基于随机模拟和搜索树构建的前沿决策算法。它在人工智能和决策优化领域起着关键作用，通过不断模拟和更新搜索树中的节点信息来找到最优决策。在该算法中，UCT 公式用于平衡搜索过程中的探索和利用。凭借其强大的功能和广泛的适用性，蒙特卡洛树搜索已成为解决复杂决策问题的关键技术之一。

  

MCTS 算法的核心过程由四个紧密相连的关键步骤组成，每个步骤在引导搜索走向最优决策方面都起着不可或缺的作用。如图 2 所示：

  

- **选择阶段**：在选择阶段，算法从根节点开始，使用特定策略（如 UCT 公式）遍历搜索树。UCT 公式为：，其中表示在状态下采取动作的累积奖励（通过过去模拟的平均奖励估计），是动作对状态的访问次数，是状态的总访问次数，是探索因子（用于平衡探索和利用）。这个公式巧妙地将节点的值与探索需求结合起来，使算法在决策过程中能够优先使用在过去经验中表现出色（高值）的节点，同时也积极探索访问次数较少（低值）但可能具有巨大潜力的节点，从而引导搜索沿着最有希望的路径进一步推进。
- **扩展阶段**：当算法到达满足一定条件的叶节点时，扩展阶段开始。此时，算法根据可能的动作或状态转换规则生成新的子节点，有效地扩大了搜索树的范围，增强了决策空间的覆盖范围。这个过程就像在未知区域开辟新的探索路径，为后续的模拟和决策提供了更多可能性。
- **模拟阶段**：一旦扩展完成，算法进入模拟阶段。从新扩展的叶节点开始，根据预定义的随机策略模拟一系列后续状态转换，直到达到终止条件。在模拟过程中，算法仔细记录所经历的奖励或值，作为评估这条模拟路径优劣的依据。这个随机模拟过程就像在决策空间中的随机漫步，通过大量模拟实验探索不同决策路径的潜在收益。
- **回传阶段**：模拟完成后，算法从叶节点回溯到根节点，沿途更新每个节点的访问次数和累计值。具体来说，将每个节点的访问次数和相应的增加量相加，并根据模拟结果添加累计奖励。通过这种方式，算法将从模拟中获得的信息反馈给搜索树，不断优化树中每个节点的统计信息，为后续选择阶段的决策提供更准确的依据。这个过程就像经验的传递和积累，使整个搜索树在连续迭代中逐渐收敛到最优或接近最优的决策路径。

  

与只关注当前最优选择（即只考虑利用项并选择最大动作）的传统贪婪算法相比，UCT 公式通过引入探索项避免过早陷入局部最优解。它可以在探索更多可能性的同时逐渐收敛到最优解或接近最优解。

  

与完全随机选择动作而不使用任何现有信息的随机搜索算法不同，UCT 公式在选择动作时考虑过去的经验（累积奖励），同时通过探索项引入一定程度的随机性，使搜索更有针对性，能够更快地找到更好的解决方案。

## 五、实验

### （一）数据集

  

- **数据集描述**：本文使用的数据集是 brca metabric（乳腺癌基因表达计算分析），这是乳腺癌研究领域常用的公开数据集，整合了基因表达数据和乳腺癌患者的临床特征，是该领域的重要资源。在来源方面，该数据集源自 METABRIC 项目或通过整合来自类似平台（如 TCGA）的开放数据生成，由 Broad 研究所的 FireBrowse 提供支持，这是一个提供癌症研究领域基因组和临床数据开放访问的平台。在数据规模上，它包含约 1900 名乳腺癌患者的详细信息，分为临床特征和分子特征两部分，每条记录代表一名患者，具体变量涵盖基本患者信息（如患者 ID、年龄、性别等）、肿瘤信息（如肿瘤类型、分子亚型等）、治疗信息（如治疗方式、是否术前治疗）、生存状态和复发信息（如患者生存状态和复发情况）、基因分型（如基于基因表达数据生成的分子特征）。在数据质量方面，数据集相对全面，但存在一些缺失值，尤其是基因分型和一些临床变量，并且类别分布存在严重不平衡，例如在 “生存状态” 中幸存者远多于死亡病例，在 “复发状态” 中未复发患者明显多于复发患者。在联邦学习过程中，1830 个训练样本平均分配给 10 个客户端（代表 10 个医疗机构）。图 3 显示了每个机构的标签分布直方图。
- **数据预处理方法**：为提高模型的训练效果和结果的可靠性，本文对数据进行了详细的数据预处理，包括特征选择和特征工程。具体步骤如下：
    - **数据清洗**：首先进行缺失值处理，删除缺失率超过 50% 的特征列，对于缺失率低于 50% 的特征，数值特征（如生存时间）用均值或中位数填充，分类特征（如分子亚型）用众数填充，并删除无意义或高度重复的特征，如部分编码列和 ID 列；此外，通过箱线图检测并去除极端异常值，以确保数据的合理分布。
    - **特征选择**：特征选择旨在从大量变量中提取对模型训练至关重要的变量，以提高模型效率和准确性。本文主要通过以下方法进行：首先是领域知识筛选，基于乳腺癌研究领域的经验知识，选择与肿瘤生物学相关性强的特征，包括临床特征（如患者年龄、肿瘤分子亚型、ER/HER2 表达状态等）、治疗方式（如手术类型、是否术前治疗）、生存和复发信息（如生存状态、复发情况）、病理分期（如肿瘤类型、肿瘤分期）；其次是统计分析，使用方差分析和卡方检验等统计方法筛选与目标变量显著相关的特征，并去除无显著相关性的特征（）；第三是特征重要性评估，使用基于树模型（如随机森林）的特征重要性得分，筛选出得分低于一定阈值的变量；第四是相关性分析，计算变量之间的皮尔逊相关系数或斯皮尔曼相关系数，去除相关性高的冗余特征（），对于具有强多重共线性的特征，使用主成分分析（PCA）进行降维。
    - **特征工程**：特征工程旨在增强模型的表达能力，通过对原始数据进行处理和转换生成更适合机器学习的特征。本文采用以下方法：首先，对于分类特征编码，使用 One-Hot 编码将分类变量（如肿瘤类型、治疗方法等）转换为数值特征，将二分类变量（如生存状态）转换为 0/1 表示；其次，在连续特征处理方面，对年龄和肿瘤大小等连续特征进行标准化，使其均值为 0，标准差为 1。对于差异较大的特征，如生存时间和复发时间，进行归一化处理，将其值缩放到 [0,1] 范围内；第三，针对数据平衡处理，针对目标变量的类别分布不平衡问题（如生存 / 死亡和复发 / 未复发），使用 SMOTE（合成少数类过采样技术）对少数类进行过采样以生成更多样本。同时，结合随机欠采样方法减少多数类的样本，从而获得平衡的数据集；第四，对于特征交互，构建交互特征。例如，通过共同考虑 “肿瘤类型” 和 “分子亚型” 生成新特征，以捕捉潜在的非线性关系；第五，对于降维，采用主成分分析（PCA），保留超过 95% 的累积方差解释率以降低特征维度，提高训练效率。

### （二）模型架构

  

- **输入层**：
    - **输入维度**：基于数据特征选择，模型的输入层维度与预处理后的数据特征数量相同。例如，假设最终特征维度为 50，则输入层节点数为 50。
    - **输入归一化**：输入数据在进入模型前进行归一化（均值为 0，标准差为 1），以加快训练速度并提高模型稳定性。
- **隐藏层**：
    - **第一层隐藏层**：该层包含 128 个神经元，使用 ReLU 作为激活函数，即，这可以减少梯度消失问题且计算开销较低，并在该层后添加一个批标准化层以加速收敛和减少内部协变量。在训练期间通过 Dropout 随机停用 20% 的节点以防止过拟合。
    - **第二层隐藏层**：这一层有 64 个神经元，同样使用 ReLU 作为激活函数，并继续使用批标准化层，通过 Dropout 技术以 30% 的概率停用节点。
    - **第三层隐藏层**：该层包含 32 个神经元，选择 ReLU 作为激活函数，并使用 Dropout 技术将节点停用概率设置为 50%，以进一步提高模型的泛化能力。
- **输出层**：
    - **单元数量**：输出层的单元数量为 2（对应于分类任务的两类：复发 / 未复发或生存 / 死亡），具体取决于任务目标。
    - **激活函数**：使用 Softmax 函数，用于输出每个类别的概率值。Softmax 函数定义为：，其中是第类的未归一化预测值，是类别总数。

### （三）参数选择细节

  

- **权重初始化**：使用适用于 ReLU 激活函数的 He Normal Initialization，它收敛速度更快且能避免梯度爆炸或消失问题，从初始化公式进行采样，其中是前一层的神经元数量。
- **优化器**：使用具有自适应学习率特征的 Adam 优化器（自适应矩估计），它在复杂模型上能实现更快的收敛，并将初始学习率设置为 0.001，同时使用学习率调度器动态调整它，以防止在训练后期收敛到次优解。
- **损失函数**：分类任务使用交叉熵损失函数（分类交叉熵），公式为，其中是真实类别，是模型预测的类别概率。
- **激活函数选择**：隐藏层统一使用引入非线性且计算高效的 ReLU 激活函数，而输出层使用适合多分类任务概率输出的 Softmax 函数。
- **正则化**：使用 Dropout 通过在不同层设置 20%、30% 和 50% 的不同停用概率来防止过拟合，同时使用 L2 正则化（权重衰减）对模型权重施加约束，以避免权重过大导致模型过于复杂。

### （四）超参数优化过程

  

超参数选择直接影响模型性能。本文通过以下步骤进行超参数优化：

  

- **超参数范围设置**：对隐藏层神经元数量测试 32、64、128、256；初始学习率从` [0.0001, 0.01]` 中选择；Dropout 比例从 0.2、0.3、0.5 中选择；Batch Size 从 16、32、64 中选择。
- **优化方法**：使用网格搜索结合 5 折交叉验证来评估超参数组合，并根据验证准确率和验证损失选择最优参数。
- **最优结果**：最优隐藏层节点配置为 128 - 64 - 32，最优学习率为 0.001，Dropout 比例在第一层为 20%，第二层为 30%，第三层为 50%，Batch Size 为 32。

### （五）批标准化的作用分析

  

在每层激活函数前添加批标准化（BN）层具有以下效果：

  

- **稳定训练过程**：通过将每批数据的均值归一化为 0 和标准差归一化为 1，减少内部协变量偏移（ICS）。
- **提高学习率**：使用更大的学习率不会导致模型发散，并加快训练速度。
- **正则化效果**：在一定程度上抑制过拟合，并通过引入噪声（每批统计数据的差异）减少对 Dropout 的依赖。

### （六）设置

  

在本研究中，详细记录原始数据样本以供后续分析。我们设置了 10 个数据持有者（类似于客户端），并确保每个持有者的数据分布平衡。在数据预处理阶段，我们应用 SMOTE 技术对数据进行过采样，以平衡数据集中的类别分布，从而提高模型的训练效果和泛化能力。除了原始的干净验证集外，我们还生成了一个预处理后的验证集，用于后续对模型性能的评估。首先，我们使用 FedAvg 算法让这 10 个数据持有者进行 20 轮联邦学习训练，以共同训练一个全局模型。在每一轮训练中，服务器将当前的全局模型参数分发给每个客户端，客户端在本地数据上训练后，将更新后的模型参数返回给服务器。服务器然后根据每个客户端的数据量对模型参数进行加权平均，以更新全局模型参数。接下来，为了比较，我们对完整数据集进行集中式训练，以训练一个参考模型，并将其与通过联邦学习训练获得的全局模型进行全面比较和分析。通过这种方式，我们能够评估联邦学习在多机构合作中的有效性和优势。此外，我们引入蒙特卡洛树搜索技术，对模型的决策过程进行深入分析。具体来说，我们根据数据特征和模型的预测结果构建可能的状态转移路径，并沿着这些路径模拟模型的决策方向。通过大量的模拟和搜索，确定最可能的决策路径，并详细分析关键决策点的特征和影响因素。在实际应用中，可以根据模型的实际性能和业务需求构建更复杂的可能路径，并使用 MCTS 来辅助理解模型行为和发现潜在风险。最后，我们使用多种评估指标，包括准确率、召回率、F1 分数、混淆矩阵和 ROC 曲线，对使用不同训练方法获得的模型进行全面评估。以直观的可视化方式呈现评估结果，以便更清晰地比较和分析模型的性能。通过上述一系列操作，我们旨在深入探索联邦学习在多个医疗机构合作中的应用效果，以及使用 MCTS 技术提高模型的可解释性和稳定性的方法。

### （七）结果

  

- **联邦学习**：我们对 10 个客户端进行了 20 轮 FL 训练。每轮训练后，在原始验证集和扰动验证集上测试该轮获得的全局模型，得到的准确率分别称为原始准确率和扰动准确率。详细准确率如图所示。从联邦训练损失曲线和准确率曲线（图 4 和图 5）可以看出，随着轮数的增加，损失逐渐降低，准确率逐渐提高。

  

经过 20 轮 FL 训练，最终的全局模型在原始验证集上达到了 72.38% 的准确率，在扰动验证集上的准确率提高到了 80.12%。使用 ROC 曲线对模型性能进行评估，发现联邦学习模型的 AUC 值为 0.73，与集中式训练模型（AUC = 0.76）相似，这表明两种方法在分类性能上差异不大。然而，联邦学习模型在隐私保护和跨机构合作方面的优势使其更适合实际医疗场景。对于集中式训练，损失曲线和准确率曲线显示出类似的趋势，但值与联邦训练不同。从这两个图中的数据可以看出，在这个特定的实验场景中，集中式训练在收敛速度和最终模型性能（包括损失值和准确率）方面优于联邦训练。从 ROC 曲线（图 6）可以看出，联邦训练和集中式训练模型的性能相似，两者的 AUC 值约为 0.75，这表明模型具有一定的判别能力。但是，FL 可以确保数据隐私和安全，在实际应用中我们更常使用 FL 模型。

  

最后，通过混淆矩阵（图 7）计算准确率的公式为：，其中是真正例，是真负例，是假正例，是假负例。这种方法可以更直观地展示模型在不同训练方法下如何对 “0：生存” 和 “1：死亡” 这两类样本进行分类，有助于进一步分析模型在实际预测中的性能。经过这些训练和评估过程，我们可以基于乳腺癌 TSV 数据集更全面地了解联邦学习和集中式学习模型，从而对模型的应用和优化做出更合理的决策。

  

- **蒙特卡洛树搜索**：我们使用基于乳腺癌 TSV 数据集训练的模型构建可能的状态转移路径。假设在乳腺癌进展预测的背景下有以下简单的转移路径：初始状态为 “早期诊断（S）”，从早期诊断到 “保守治疗（A）” 的可能转移概率为 0.6，到 “手术治疗（B）” 的概率为 0.4。从 “保守治疗（A）” 到 “缓解（C）” 的可能转移概率为 0.7，到 “进展（D）” 的概率为 0.3。从 “手术治疗（B）” 到 “康复（E）” 的概率为 0.8，到 “复发（F）” 的概率为 0.2。我们从初始状态 “S” 开始进行 200 次 MCTS 模拟。

## 六、结论

  

本研究专注于乳腺癌的诊断，采用相关的数据处理、模型训练和评估方法进行了深入研究，并取得了显著成果。在数据处理方面，对乳腺癌 TSV 数据集进行了精心预处理，如通过特征工程和数据增强等操作，有效提高了数据质量，改善了类别不平衡的状况。对集中式和联邦式训练的比较表明，它们在模型性能方面各有优势。集中式训练依赖完整的数据集，训练过程相对简单直接。而联邦式训练则利用了多个模拟医疗机构数据的协同作用，在数据隐私保护方面具有独特优势。经过多轮全球训练，其模型在验证集上也表现出良好的准确性和稳定性。在本研究中，蒙特卡洛树搜索为乳腺癌生存状态的动态预测提供了新的思路。通过模拟患者状态的转移路径，MCTS 不仅揭示了关键决策点之间的潜在相关性，还为个性化治疗策略的制定提供了直观的支持工具。在实际应用中，MCTS 的灵活性和适应性为复杂临床场景中的风险评估和治疗优化提供了巨大潜力。实验结果表明，本研究为乳腺癌诊断领域的模型构建和应用提供了有价值的参考。数据处理方法、不同训练方法效果的呈现以及 MCTS 的创新应用尝试，都为后续研究和实践奠定了坚实的基础，有望进一步推动医疗诊断技术的发展和优化。